[2020-01-19 18:55:28,775] {jobs.py:368} INFO - Started process (PID=64839) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:55:33,783] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:55:33,789] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:55:38,959] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:55:39,141] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 10.366 seconds
[2020-01-19 18:55:40,207] {jobs.py:368} INFO - Started process (PID=64910) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:55:45,215] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:55:45,217] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:55:48,249] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:55:48,426] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.220 seconds
[2020-01-19 18:55:49,558] {jobs.py:368} INFO - Started process (PID=64973) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:55:54,567] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:55:54,569] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:55:57,746] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:55:57,917] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.358 seconds
[2020-01-19 18:55:58,980] {jobs.py:368} INFO - Started process (PID=65074) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:56:03,989] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:56:03,992] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:56:06,782] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:56:06,958] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 7.979 seconds
[2020-01-19 18:56:08,016] {jobs.py:368} INFO - Started process (PID=65140) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:56:13,027] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:56:13,031] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:56:15,850] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:56:16,022] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.006 seconds
[2020-01-19 18:56:17,146] {jobs.py:368} INFO - Started process (PID=65199) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:56:22,152] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:56:22,154] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:56:25,047] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:56:25,219] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.073 seconds
[2020-01-19 18:56:26,277] {jobs.py:368} INFO - Started process (PID=65264) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:56:31,285] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:56:31,288] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:56:34,796] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:56:34,950] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.674 seconds
[2020-01-19 18:56:36,010] {jobs.py:368} INFO - Started process (PID=65367) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:56:41,019] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:56:41,021] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:56:43,746] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:56:43,951] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 7.941 seconds
[2020-01-19 18:56:45,066] {jobs.py:368} INFO - Started process (PID=65432) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:56:50,075] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:56:50,079] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:56:52,816] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:56:53,054] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 7.988 seconds
[2020-01-19 18:56:54,113] {jobs.py:368} INFO - Started process (PID=65485) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:56:59,117] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:56:59,124] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:57:01,969] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:57:02,134] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.021 seconds
[2020-01-19 18:57:03,237] {jobs.py:368} INFO - Started process (PID=65550) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:57:08,241] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:57:08,243] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:57:10,874] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:57:11,115] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 7.878 seconds
[2020-01-19 18:57:12,193] {jobs.py:368} INFO - Started process (PID=65632) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:57:17,199] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:57:17,204] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:57:20,527] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:57:20,692] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.499 seconds
[2020-01-19 18:57:21,824] {jobs.py:368} INFO - Started process (PID=65689) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:57:26,833] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:57:26,838] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:57:29,998] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:57:30,218] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.395 seconds
[2020-01-19 18:57:31,285] {jobs.py:368} INFO - Started process (PID=65754) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:57:36,293] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:57:36,299] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:57:39,613] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:57:39,780] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.496 seconds
[2020-01-19 18:57:40,902] {jobs.py:368} INFO - Started process (PID=65836) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:57:45,907] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:57:45,910] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:57:48,778] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:57:48,994] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.092 seconds
[2020-01-19 18:57:50,051] {jobs.py:368} INFO - Started process (PID=65893) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:57:55,056] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:57:55,059] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:57:57,711] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:57:57,884] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 7.832 seconds
[2020-01-19 18:57:58,960] {jobs.py:368} INFO - Started process (PID=65964) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:58:03,965] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:58:03,968] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:58:06,656] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:58:06,814] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 7.855 seconds
[2020-01-19 18:58:07,889] {jobs.py:368} INFO - Started process (PID=66030) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:58:12,893] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:58:12,895] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:58:15,871] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:58:16,060] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.171 seconds
[2020-01-19 18:58:17,120] {jobs.py:368} INFO - Started process (PID=66116) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:58:22,125] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:58:22,132] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:58:24,932] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:58:25,086] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 7.966 seconds
[2020-01-19 18:58:26,163] {jobs.py:368} INFO - Started process (PID=66179) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:58:31,170] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:58:31,172] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:58:33,934] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:58:34,104] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 7.940 seconds
[2020-01-19 18:58:35,189] {jobs.py:368} INFO - Started process (PID=66244) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:58:40,194] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:58:40,199] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:58:42,940] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:58:43,097] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 7.908 seconds
[2020-01-19 18:58:44,199] {jobs.py:368} INFO - Started process (PID=66310) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:58:49,204] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:58:49,220] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:58:52,304] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:58:52,500] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.301 seconds
[2020-01-19 18:58:53,628] {jobs.py:368} INFO - Started process (PID=66411) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:58:58,636] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:58:58,638] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:59:01,503] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:59:01,686] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.059 seconds
[2020-01-19 18:59:02,753] {jobs.py:368} INFO - Started process (PID=66479) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:59:07,762] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:59:07,764] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:59:10,673] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:59:10,853] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.100 seconds
[2020-01-19 18:59:11,922] {jobs.py:368} INFO - Started process (PID=66544) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:59:16,931] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:59:16,933] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:59:19,854] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:59:20,002] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.080 seconds
[2020-01-19 18:59:21,074] {jobs.py:368} INFO - Started process (PID=66612) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:59:26,083] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:59:26,085] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:59:28,905] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:59:29,071] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 18:59:29,122] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-01 00:00:00: scheduled__2015-06-01T00:00:00, externally triggered: False>
[2020-01-19 18:59:29,124] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-01 00:00:00: scheduled__2015-06-01T00:00:00, externally triggered: False>
[2020-01-19 18:59:29,134] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 18:59:29,149] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-01 00:00:00 [scheduled]> in ORM
[2020-01-19 18:59:29,160] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-01 00:00:00 [scheduled]> in ORM
[2020-01-19 18:59:29,178] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.104 seconds
[2020-01-19 18:59:30,269] {jobs.py:368} INFO - Started process (PID=66696) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:59:35,273] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 18:59:35,279] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 18:59:38,158] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 18:59:38,307] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 18:59:38,334] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-02 00:00:00: scheduled__2015-06-02T00:00:00, externally triggered: False>
[2020-01-19 18:59:38,337] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-01 00:00:00: scheduled__2015-06-01T00:00:00, externally triggered: False>
[2020-01-19 18:59:38,344] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-02 00:00:00: scheduled__2015-06-02T00:00:00, externally triggered: False>
[2020-01-19 18:59:38,356] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 18:59:38,367] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-02 00:00:00 [scheduled]> in ORM
[2020-01-19 18:59:38,373] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-02 00:00:00 [scheduled]> in ORM
[2020-01-19 18:59:38,387] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.118 seconds
[2020-01-19 19:02:30,937] {jobs.py:368} INFO - Started process (PID=67896) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:02:35,967] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:02:35,969] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:02:38,692] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:02:38,921] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:02:38,944] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-03 00:00:00: scheduled__2015-06-03T00:00:00, externally triggered: False>
[2020-01-19 19:02:38,947] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-01 00:00:00: scheduled__2015-06-01T00:00:00, externally triggered: False>
[2020-01-19 19:02:38,964] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-02 00:00:00: scheduled__2015-06-02T00:00:00, externally triggered: False>
[2020-01-19 19:02:38,980] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-03 00:00:00: scheduled__2015-06-03T00:00:00, externally triggered: False>
[2020-01-19 19:02:38,987] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2020-01-19 09:59:39.776829: manual__2020-01-19T09:59:39.776829, externally triggered: True>
[2020-01-19 19:02:39,000] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:02:39,010] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-03 00:00:00 [scheduled]> in ORM
[2020-01-19 19:02:39,014] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-03 00:00:00 [scheduled]> in ORM
[2020-01-19 19:02:39,019] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2020-01-19 09:59:39.776829 [scheduled]> in ORM
[2020-01-19 19:02:39,024] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2020-01-19 09:59:39.776829 [scheduled]> in ORM
[2020-01-19 19:02:39,038] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.100 seconds
[2020-01-19 19:05:27,969] {jobs.py:368} INFO - Started process (PID=69121) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:05:32,978] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:05:32,980] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:05:35,895] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:05:36,135] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:05:36,161] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-04 00:00:00: scheduled__2015-06-04T00:00:00, externally triggered: False>
[2020-01-19 19:05:36,167] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-03 00:00:00: scheduled__2015-06-03T00:00:00, externally triggered: False>
[2020-01-19 19:05:36,182] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-04 00:00:00: scheduled__2015-06-04T00:00:00, externally triggered: False>
[2020-01-19 19:05:36,190] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2020-01-19 09:59:39.776829: manual__2020-01-19T09:59:39.776829, externally triggered: True>
[2020-01-19 19:05:36,201] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:05:36,211] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-04 00:00:00 [scheduled]> in ORM
[2020-01-19 19:05:36,217] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-04 00:00:00 [scheduled]> in ORM
[2020-01-19 19:05:36,233] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.263 seconds
[2020-01-19 19:07:00,410] {jobs.py:368} INFO - Started process (PID=69759) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:07:05,421] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:07:05,424] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:07:08,588] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:07:08,829] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:07:08,855] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-05 00:00:00: scheduled__2015-06-05T00:00:00, externally triggered: False>
[2020-01-19 19:07:08,857] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-04 00:00:00: scheduled__2015-06-04T00:00:00, externally triggered: False>
[2020-01-19 19:07:08,867] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-05 00:00:00: scheduled__2015-06-05T00:00:00, externally triggered: False>
[2020-01-19 19:07:08,876] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:07:08,886] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-05 00:00:00 [scheduled]> in ORM
[2020-01-19 19:07:08,892] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-05 00:00:00 [scheduled]> in ORM
[2020-01-19 19:07:08,911] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.501 seconds
[2020-01-19 19:08:33,766] {jobs.py:368} INFO - Started process (PID=70420) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:08:38,773] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:08:38,775] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:08:41,943] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:08:42,081] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:08:42,102] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-06 00:00:00: scheduled__2015-06-06T00:00:00, externally triggered: False>
[2020-01-19 19:08:42,104] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-05 00:00:00: scheduled__2015-06-05T00:00:00, externally triggered: False>
[2020-01-19 19:08:42,115] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-06 00:00:00: scheduled__2015-06-06T00:00:00, externally triggered: False>
[2020-01-19 19:08:42,125] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:08:42,139] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-06 00:00:00 [scheduled]> in ORM
[2020-01-19 19:08:42,144] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-06 00:00:00 [scheduled]> in ORM
[2020-01-19 19:08:42,163] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.396 seconds
[2020-01-19 19:10:06,954] {jobs.py:368} INFO - Started process (PID=71091) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:10:11,960] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:10:11,967] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:10:15,093] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:10:15,260] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:10:15,285] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-07 00:00:00: scheduled__2015-06-07T00:00:00, externally triggered: False>
[2020-01-19 19:10:15,288] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-06 00:00:00: scheduled__2015-06-06T00:00:00, externally triggered: False>
[2020-01-19 19:10:15,298] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-07 00:00:00: scheduled__2015-06-07T00:00:00, externally triggered: False>
[2020-01-19 19:10:15,309] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:10:15,320] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-07 00:00:00 [scheduled]> in ORM
[2020-01-19 19:10:15,325] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-07 00:00:00 [scheduled]> in ORM
[2020-01-19 19:10:15,339] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.385 seconds
[2020-01-19 19:11:40,254] {jobs.py:368} INFO - Started process (PID=71674) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:11:45,262] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:11:45,264] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:11:48,249] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:11:48,404] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:11:48,432] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-08 00:00:00: scheduled__2015-06-08T00:00:00, externally triggered: False>
[2020-01-19 19:11:48,436] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-07 00:00:00: scheduled__2015-06-07T00:00:00, externally triggered: False>
[2020-01-19 19:11:48,452] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-08 00:00:00: scheduled__2015-06-08T00:00:00, externally triggered: False>
[2020-01-19 19:11:48,462] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:11:48,471] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-08 00:00:00 [scheduled]> in ORM
[2020-01-19 19:11:48,477] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-08 00:00:00 [scheduled]> in ORM
[2020-01-19 19:11:48,489] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.235 seconds
[2020-01-19 19:13:14,765] {jobs.py:368} INFO - Started process (PID=72198) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:13:19,775] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:13:19,778] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:13:22,828] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:13:22,985] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:13:23,015] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-09 00:00:00: scheduled__2015-06-09T00:00:00, externally triggered: False>
[2020-01-19 19:13:23,018] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-08 00:00:00: scheduled__2015-06-08T00:00:00, externally triggered: False>
[2020-01-19 19:13:23,033] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-09 00:00:00: scheduled__2015-06-09T00:00:00, externally triggered: False>
[2020-01-19 19:13:23,044] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:13:23,054] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-09 00:00:00 [scheduled]> in ORM
[2020-01-19 19:13:23,060] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-09 00:00:00 [scheduled]> in ORM
[2020-01-19 19:13:23,075] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.309 seconds
[2020-01-19 19:14:47,845] {jobs.py:368} INFO - Started process (PID=73029) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:14:52,851] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:14:52,854] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:14:56,043] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:14:56,234] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:14:56,262] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-10 00:00:00: scheduled__2015-06-10T00:00:00, externally triggered: False>
[2020-01-19 19:14:56,265] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-09 00:00:00: scheduled__2015-06-09T00:00:00, externally triggered: False>
[2020-01-19 19:14:56,281] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-10 00:00:00: scheduled__2015-06-10T00:00:00, externally triggered: False>
[2020-01-19 19:14:56,299] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:14:56,319] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-10 00:00:00 [scheduled]> in ORM
[2020-01-19 19:14:56,328] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-10 00:00:00 [scheduled]> in ORM
[2020-01-19 19:14:56,350] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.505 seconds
[2020-01-19 19:16:21,911] {jobs.py:368} INFO - Started process (PID=73797) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:16:26,922] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:16:26,925] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:16:29,752] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:16:29,973] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:16:29,994] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-11 00:00:00: scheduled__2015-06-11T00:00:00, externally triggered: False>
[2020-01-19 19:16:29,996] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-10 00:00:00: scheduled__2015-06-10T00:00:00, externally triggered: False>
[2020-01-19 19:16:30,007] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-11 00:00:00: scheduled__2015-06-11T00:00:00, externally triggered: False>
[2020-01-19 19:16:30,017] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:16:30,025] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-11 00:00:00 [scheduled]> in ORM
[2020-01-19 19:16:30,031] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-11 00:00:00 [scheduled]> in ORM
[2020-01-19 19:16:30,043] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.132 seconds
[2020-01-19 19:17:54,741] {jobs.py:368} INFO - Started process (PID=74551) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:17:59,746] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:17:59,748] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:18:02,640] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:18:02,819] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:18:02,847] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-12 00:00:00: scheduled__2015-06-12T00:00:00, externally triggered: False>
[2020-01-19 19:18:02,849] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-11 00:00:00: scheduled__2015-06-11T00:00:00, externally triggered: False>
[2020-01-19 19:18:02,863] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-12 00:00:00: scheduled__2015-06-12T00:00:00, externally triggered: False>
[2020-01-19 19:18:02,876] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:18:02,887] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-12 00:00:00 [scheduled]> in ORM
[2020-01-19 19:18:02,893] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-12 00:00:00 [scheduled]> in ORM
[2020-01-19 19:18:02,908] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.167 seconds
[2020-01-19 19:19:27,246] {jobs.py:368} INFO - Started process (PID=76408) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:19:32,257] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:19:32,263] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:19:35,483] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:19:35,632] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:19:35,657] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-13 00:00:00: scheduled__2015-06-13T00:00:00, externally triggered: False>
[2020-01-19 19:19:35,661] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-12 00:00:00: scheduled__2015-06-12T00:00:00, externally triggered: False>
[2020-01-19 19:19:35,672] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-13 00:00:00: scheduled__2015-06-13T00:00:00, externally triggered: False>
[2020-01-19 19:19:35,682] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:19:35,691] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-13 00:00:00 [scheduled]> in ORM
[2020-01-19 19:19:35,697] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-13 00:00:00 [scheduled]> in ORM
[2020-01-19 19:19:35,709] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.464 seconds
[2020-01-19 19:21:01,043] {jobs.py:368} INFO - Started process (PID=77046) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:21:06,052] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:21:06,056] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:21:09,405] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:21:09,618] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:21:09,643] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-14 00:00:00: scheduled__2015-06-14T00:00:00, externally triggered: False>
[2020-01-19 19:21:09,646] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-13 00:00:00: scheduled__2015-06-13T00:00:00, externally triggered: False>
[2020-01-19 19:21:09,658] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-14 00:00:00: scheduled__2015-06-14T00:00:00, externally triggered: False>
[2020-01-19 19:21:09,667] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:21:09,676] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-14 00:00:00 [scheduled]> in ORM
[2020-01-19 19:21:09,682] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-14 00:00:00 [scheduled]> in ORM
[2020-01-19 19:21:09,696] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.652 seconds
[2020-01-19 19:22:34,605] {jobs.py:368} INFO - Started process (PID=77858) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:22:39,610] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:22:39,612] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:22:42,619] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:22:42,801] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:22:42,855] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-15 00:00:00: scheduled__2015-06-15T00:00:00, externally triggered: False>
[2020-01-19 19:22:42,858] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-14 00:00:00: scheduled__2015-06-14T00:00:00, externally triggered: False>
[2020-01-19 19:22:42,871] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-15 00:00:00: scheduled__2015-06-15T00:00:00, externally triggered: False>
[2020-01-19 19:22:42,881] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:22:42,891] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-15 00:00:00 [scheduled]> in ORM
[2020-01-19 19:22:42,896] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-15 00:00:00 [scheduled]> in ORM
[2020-01-19 19:22:42,911] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.306 seconds
[2020-01-19 19:24:07,581] {jobs.py:368} INFO - Started process (PID=78553) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:24:12,589] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:24:12,591] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:24:15,916] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:24:16,163] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:24:16,207] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-16 00:00:00: scheduled__2015-06-16T00:00:00, externally triggered: False>
[2020-01-19 19:24:16,212] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-15 00:00:00: scheduled__2015-06-15T00:00:00, externally triggered: False>
[2020-01-19 19:24:16,231] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-16 00:00:00: scheduled__2015-06-16T00:00:00, externally triggered: False>
[2020-01-19 19:24:16,242] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:24:16,254] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-16 00:00:00 [scheduled]> in ORM
[2020-01-19 19:24:16,260] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-16 00:00:00 [scheduled]> in ORM
[2020-01-19 19:24:16,277] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.696 seconds
[2020-01-19 19:25:40,935] {jobs.py:368} INFO - Started process (PID=79200) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:25:45,940] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:25:45,942] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:25:49,039] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:25:49,250] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:25:49,287] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-17 00:00:00: scheduled__2015-06-17T00:00:00, externally triggered: False>
[2020-01-19 19:25:49,291] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-16 00:00:00: scheduled__2015-06-16T00:00:00, externally triggered: False>
[2020-01-19 19:25:49,314] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-17 00:00:00: scheduled__2015-06-17T00:00:00, externally triggered: False>
[2020-01-19 19:25:49,329] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:25:49,412] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-17 00:00:00 [scheduled]> in ORM
[2020-01-19 19:25:49,426] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-17 00:00:00 [scheduled]> in ORM
[2020-01-19 19:25:49,461] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.525 seconds
[2020-01-19 19:27:14,139] {jobs.py:368} INFO - Started process (PID=79915) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:27:19,149] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:27:19,151] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:27:22,097] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:27:22,261] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:27:22,288] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-18 00:00:00: scheduled__2015-06-18T00:00:00, externally triggered: False>
[2020-01-19 19:27:22,292] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-17 00:00:00: scheduled__2015-06-17T00:00:00, externally triggered: False>
[2020-01-19 19:27:22,307] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-18 00:00:00: scheduled__2015-06-18T00:00:00, externally triggered: False>
[2020-01-19 19:27:22,320] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:27:22,333] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-18 00:00:00 [scheduled]> in ORM
[2020-01-19 19:27:22,339] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-18 00:00:00 [scheduled]> in ORM
[2020-01-19 19:27:22,355] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.217 seconds
[2020-01-19 19:28:47,051] {jobs.py:368} INFO - Started process (PID=80655) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:28:52,057] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:28:52,059] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:28:55,162] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:28:55,341] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:28:55,376] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-19 00:00:00: scheduled__2015-06-19T00:00:00, externally triggered: False>
[2020-01-19 19:28:55,379] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-18 00:00:00: scheduled__2015-06-18T00:00:00, externally triggered: False>
[2020-01-19 19:28:55,394] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-19 00:00:00: scheduled__2015-06-19T00:00:00, externally triggered: False>
[2020-01-19 19:28:55,407] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:28:55,419] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-19 00:00:00 [scheduled]> in ORM
[2020-01-19 19:28:55,425] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-19 00:00:00 [scheduled]> in ORM
[2020-01-19 19:28:55,439] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.388 seconds
[2020-01-19 19:30:20,801] {jobs.py:368} INFO - Started process (PID=81181) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:30:25,808] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:30:25,818] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:30:29,045] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:30:29,191] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:30:29,225] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-20 00:00:00: scheduled__2015-06-20T00:00:00, externally triggered: False>
[2020-01-19 19:30:29,228] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-19 00:00:00: scheduled__2015-06-19T00:00:00, externally triggered: False>
[2020-01-19 19:30:29,240] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-20 00:00:00: scheduled__2015-06-20T00:00:00, externally triggered: False>
[2020-01-19 19:30:29,252] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:30:29,273] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-20 00:00:00 [scheduled]> in ORM
[2020-01-19 19:30:29,278] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-20 00:00:00 [scheduled]> in ORM
[2020-01-19 19:30:29,292] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.491 seconds
[2020-01-19 19:31:54,216] {jobs.py:368} INFO - Started process (PID=81915) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:31:59,223] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:31:59,224] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:32:02,731] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:32:02,974] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:32:03,005] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-21 00:00:00: scheduled__2015-06-21T00:00:00, externally triggered: False>
[2020-01-19 19:32:03,009] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-20 00:00:00: scheduled__2015-06-20T00:00:00, externally triggered: False>
[2020-01-19 19:32:03,021] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-21 00:00:00: scheduled__2015-06-21T00:00:00, externally triggered: False>
[2020-01-19 19:32:03,048] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:32:03,066] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-21 00:00:00 [scheduled]> in ORM
[2020-01-19 19:32:03,082] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-21 00:00:00 [scheduled]> in ORM
[2020-01-19 19:32:03,102] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.886 seconds
[2020-01-19 19:33:27,612] {jobs.py:368} INFO - Started process (PID=82551) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:33:32,618] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:33:32,627] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:33:36,155] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:33:36,304] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:33:36,327] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-22 00:00:00: scheduled__2015-06-22T00:00:00, externally triggered: False>
[2020-01-19 19:33:36,329] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-21 00:00:00: scheduled__2015-06-21T00:00:00, externally triggered: False>
[2020-01-19 19:33:36,340] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-22 00:00:00: scheduled__2015-06-22T00:00:00, externally triggered: False>
[2020-01-19 19:33:36,350] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:33:36,360] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-22 00:00:00 [scheduled]> in ORM
[2020-01-19 19:33:36,367] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-22 00:00:00 [scheduled]> in ORM
[2020-01-19 19:33:36,382] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.770 seconds
[2020-01-19 19:35:01,450] {jobs.py:368} INFO - Started process (PID=83084) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:35:06,456] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:35:06,458] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:35:09,743] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:35:10,045] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:35:10,089] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-23 00:00:00: scheduled__2015-06-23T00:00:00, externally triggered: False>
[2020-01-19 19:35:10,092] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-22 00:00:00: scheduled__2015-06-22T00:00:00, externally triggered: False>
[2020-01-19 19:35:10,104] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-23 00:00:00: scheduled__2015-06-23T00:00:00, externally triggered: False>
[2020-01-19 19:35:10,117] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:35:10,131] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-23 00:00:00 [scheduled]> in ORM
[2020-01-19 19:35:10,139] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-23 00:00:00 [scheduled]> in ORM
[2020-01-19 19:35:10,162] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.712 seconds
[2020-01-19 19:36:34,965] {jobs.py:368} INFO - Started process (PID=84061) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:36:39,973] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:36:39,976] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:36:44,006] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:36:44,214] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:36:44,243] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-24 00:00:00: scheduled__2015-06-24T00:00:00, externally triggered: False>
[2020-01-19 19:36:44,246] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-23 00:00:00: scheduled__2015-06-23T00:00:00, externally triggered: False>
[2020-01-19 19:36:44,260] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-24 00:00:00: scheduled__2015-06-24T00:00:00, externally triggered: False>
[2020-01-19 19:36:44,275] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:36:44,288] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-24 00:00:00 [scheduled]> in ORM
[2020-01-19 19:36:44,301] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-24 00:00:00 [scheduled]> in ORM
[2020-01-19 19:36:44,332] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 9.367 seconds
[2020-01-19 19:38:09,785] {jobs.py:368} INFO - Started process (PID=84779) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:38:14,791] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:38:14,794] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:38:18,035] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:38:18,205] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:38:18,232] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-25 00:00:00: scheduled__2015-06-25T00:00:00, externally triggered: False>
[2020-01-19 19:38:18,236] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-24 00:00:00: scheduled__2015-06-24T00:00:00, externally triggered: False>
[2020-01-19 19:38:18,259] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-25 00:00:00: scheduled__2015-06-25T00:00:00, externally triggered: False>
[2020-01-19 19:38:18,277] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:38:18,292] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-25 00:00:00 [scheduled]> in ORM
[2020-01-19 19:38:18,298] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-25 00:00:00 [scheduled]> in ORM
[2020-01-19 19:38:18,319] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.534 seconds
[2020-01-19 19:39:43,067] {jobs.py:368} INFO - Started process (PID=85479) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:39:48,078] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:39:48,080] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:39:51,742] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:39:51,914] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:39:51,939] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-26 00:00:00: scheduled__2015-06-26T00:00:00, externally triggered: False>
[2020-01-19 19:39:51,941] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-25 00:00:00: scheduled__2015-06-25T00:00:00, externally triggered: False>
[2020-01-19 19:39:51,954] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-26 00:00:00: scheduled__2015-06-26T00:00:00, externally triggered: False>
[2020-01-19 19:39:51,968] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:39:51,980] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-26 00:00:00 [scheduled]> in ORM
[2020-01-19 19:39:51,986] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-26 00:00:00 [scheduled]> in ORM
[2020-01-19 19:39:52,003] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.936 seconds
[2020-01-19 19:41:17,119] {jobs.py:368} INFO - Started process (PID=86343) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:41:22,127] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:41:22,129] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:41:25,600] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:41:25,806] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:41:25,839] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-27 00:00:00: scheduled__2015-06-27T00:00:00, externally triggered: False>
[2020-01-19 19:41:25,842] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-26 00:00:00: scheduled__2015-06-26T00:00:00, externally triggered: False>
[2020-01-19 19:41:25,857] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-27 00:00:00: scheduled__2015-06-27T00:00:00, externally triggered: False>
[2020-01-19 19:41:25,868] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:41:25,884] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-27 00:00:00 [scheduled]> in ORM
[2020-01-19 19:41:25,891] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-27 00:00:00 [scheduled]> in ORM
[2020-01-19 19:41:25,908] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.790 seconds
[2020-01-19 19:42:50,857] {jobs.py:368} INFO - Started process (PID=86985) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:42:55,863] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:42:55,865] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:42:58,975] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:42:59,145] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:42:59,168] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-28 00:00:00: scheduled__2015-06-28T00:00:00, externally triggered: False>
[2020-01-19 19:42:59,170] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-27 00:00:00: scheduled__2015-06-27T00:00:00, externally triggered: False>
[2020-01-19 19:42:59,182] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-28 00:00:00: scheduled__2015-06-28T00:00:00, externally triggered: False>
[2020-01-19 19:42:59,193] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:42:59,206] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-28 00:00:00 [scheduled]> in ORM
[2020-01-19 19:42:59,213] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-28 00:00:00 [scheduled]> in ORM
[2020-01-19 19:42:59,228] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.371 seconds
[2020-01-19 19:44:24,029] {jobs.py:368} INFO - Started process (PID=87673) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:44:29,033] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:44:29,036] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:44:32,368] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:44:32,547] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:44:32,591] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-29 00:00:00: scheduled__2015-06-29T00:00:00, externally triggered: False>
[2020-01-19 19:44:32,593] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-28 00:00:00: scheduled__2015-06-28T00:00:00, externally triggered: False>
[2020-01-19 19:44:32,611] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-29 00:00:00: scheduled__2015-06-29T00:00:00, externally triggered: False>
[2020-01-19 19:44:32,626] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:44:32,639] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-29 00:00:00 [scheduled]> in ORM
[2020-01-19 19:44:32,647] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-29 00:00:00 [scheduled]> in ORM
[2020-01-19 19:44:32,671] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.642 seconds
[2020-01-19 19:45:57,993] {jobs.py:368} INFO - Started process (PID=88366) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:46:03,001] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:46:03,002] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:46:06,298] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:46:06,481] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:46:06,512] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-06-30 00:00:00: scheduled__2015-06-30T00:00:00, externally triggered: False>
[2020-01-19 19:46:06,518] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-29 00:00:00: scheduled__2015-06-29T00:00:00, externally triggered: False>
[2020-01-19 19:46:06,538] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-30 00:00:00: scheduled__2015-06-30T00:00:00, externally triggered: False>
[2020-01-19 19:46:06,557] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:46:06,580] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-06-30 00:00:00 [scheduled]> in ORM
[2020-01-19 19:46:06,587] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-06-30 00:00:00 [scheduled]> in ORM
[2020-01-19 19:46:06,603] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.610 seconds
[2020-01-19 19:47:33,055] {jobs.py:368} INFO - Started process (PID=89016) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:47:38,060] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:47:38,066] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:47:41,536] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:47:41,718] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:47:41,760] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-01 00:00:00: scheduled__2015-07-01T00:00:00, externally triggered: False>
[2020-01-19 19:47:41,762] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-06-30 00:00:00: scheduled__2015-06-30T00:00:00, externally triggered: False>
[2020-01-19 19:47:41,773] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-01 00:00:00: scheduled__2015-07-01T00:00:00, externally triggered: False>
[2020-01-19 19:47:41,784] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:47:41,793] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-01 00:00:00 [scheduled]> in ORM
[2020-01-19 19:47:41,803] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-01 00:00:00 [scheduled]> in ORM
[2020-01-19 19:47:41,819] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.764 seconds
[2020-01-19 19:49:06,275] {jobs.py:368} INFO - Started process (PID=89784) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:49:11,281] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:49:11,283] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:49:14,270] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:49:14,428] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:49:14,449] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-02 00:00:00: scheduled__2015-07-02T00:00:00, externally triggered: False>
[2020-01-19 19:49:14,452] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-01 00:00:00: scheduled__2015-07-01T00:00:00, externally triggered: False>
[2020-01-19 19:49:14,463] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-02 00:00:00: scheduled__2015-07-02T00:00:00, externally triggered: False>
[2020-01-19 19:49:14,473] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:49:14,482] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-02 00:00:00 [scheduled]> in ORM
[2020-01-19 19:49:14,488] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-02 00:00:00 [scheduled]> in ORM
[2020-01-19 19:49:14,500] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.225 seconds
[2020-01-19 19:50:45,881] {jobs.py:368} INFO - Started process (PID=90532) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:50:50,887] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:50:50,889] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:50:54,276] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:50:54,637] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:50:54,673] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-03 00:00:00: scheduled__2015-07-03T00:00:00, externally triggered: False>
[2020-01-19 19:50:54,676] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-02 00:00:00: scheduled__2015-07-02T00:00:00, externally triggered: False>
[2020-01-19 19:50:54,691] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-03 00:00:00: scheduled__2015-07-03T00:00:00, externally triggered: False>
[2020-01-19 19:50:54,707] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:50:54,725] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-03 00:00:00 [scheduled]> in ORM
[2020-01-19 19:50:54,785] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-03 00:00:00 [scheduled]> in ORM
[2020-01-19 19:50:54,848] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.967 seconds
[2020-01-19 19:52:22,116] {jobs.py:368} INFO - Started process (PID=91223) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:52:27,121] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:52:27,123] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:52:30,562] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:52:30,703] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:52:30,727] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-04 00:00:00: scheduled__2015-07-04T00:00:00, externally triggered: False>
[2020-01-19 19:52:30,730] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-03 00:00:00: scheduled__2015-07-03T00:00:00, externally triggered: False>
[2020-01-19 19:52:30,743] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-04 00:00:00: scheduled__2015-07-04T00:00:00, externally triggered: False>
[2020-01-19 19:52:30,755] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:52:30,764] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-04 00:00:00 [scheduled]> in ORM
[2020-01-19 19:52:30,770] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-04 00:00:00 [scheduled]> in ORM
[2020-01-19 19:52:30,783] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.667 seconds
[2020-01-19 19:53:55,313] {jobs.py:368} INFO - Started process (PID=91863) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:54:00,322] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:54:00,324] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:54:04,031] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:54:04,168] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:54:04,199] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-05 00:00:00: scheduled__2015-07-05T00:00:00, externally triggered: False>
[2020-01-19 19:54:04,202] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-04 00:00:00: scheduled__2015-07-04T00:00:00, externally triggered: False>
[2020-01-19 19:54:04,212] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-05 00:00:00: scheduled__2015-07-05T00:00:00, externally triggered: False>
[2020-01-19 19:54:04,222] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:54:04,233] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-05 00:00:00 [scheduled]> in ORM
[2020-01-19 19:54:04,240] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-05 00:00:00 [scheduled]> in ORM
[2020-01-19 19:54:04,254] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.941 seconds
[2020-01-19 19:55:29,250] {jobs.py:368} INFO - Started process (PID=92481) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:55:34,255] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:55:34,258] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:55:37,306] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:55:37,479] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:55:37,502] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-06 00:00:00: scheduled__2015-07-06T00:00:00, externally triggered: False>
[2020-01-19 19:55:37,504] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-05 00:00:00: scheduled__2015-07-05T00:00:00, externally triggered: False>
[2020-01-19 19:55:37,514] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-06 00:00:00: scheduled__2015-07-06T00:00:00, externally triggered: False>
[2020-01-19 19:55:37,526] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:55:37,535] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-06 00:00:00 [scheduled]> in ORM
[2020-01-19 19:55:37,541] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-06 00:00:00 [scheduled]> in ORM
[2020-01-19 19:55:37,557] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.307 seconds
[2020-01-19 19:57:02,148] {jobs.py:368} INFO - Started process (PID=93026) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:57:07,161] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:57:07,163] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:57:10,082] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:57:10,242] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:57:10,286] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-07 00:00:00: scheduled__2015-07-07T00:00:00, externally triggered: False>
[2020-01-19 19:57:10,289] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-06 00:00:00: scheduled__2015-07-06T00:00:00, externally triggered: False>
[2020-01-19 19:57:10,301] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-07 00:00:00: scheduled__2015-07-07T00:00:00, externally triggered: False>
[2020-01-19 19:57:10,319] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:57:10,336] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-07 00:00:00 [scheduled]> in ORM
[2020-01-19 19:57:10,348] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-07 00:00:00 [scheduled]> in ORM
[2020-01-19 19:57:10,375] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.226 seconds
[2020-01-19 19:58:34,901] {jobs.py:368} INFO - Started process (PID=93596) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:58:39,906] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 19:58:39,909] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 19:58:44,004] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 19:58:44,536] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 19:58:44,580] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-08 00:00:00: scheduled__2015-07-08T00:00:00, externally triggered: False>
[2020-01-19 19:58:44,585] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-07 00:00:00: scheduled__2015-07-07T00:00:00, externally triggered: False>
[2020-01-19 19:58:44,670] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-08 00:00:00: scheduled__2015-07-08T00:00:00, externally triggered: False>
[2020-01-19 19:58:44,697] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 19:58:44,731] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-08 00:00:00 [scheduled]> in ORM
[2020-01-19 19:58:44,740] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-08 00:00:00 [scheduled]> in ORM
[2020-01-19 19:58:44,768] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 9.867 seconds
[2020-01-19 20:00:12,155] {jobs.py:368} INFO - Started process (PID=94294) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:00:17,163] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 20:00:17,165] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 20:00:20,189] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:00:20,347] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 20:00:20,377] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-09 00:00:00: scheduled__2015-07-09T00:00:00, externally triggered: False>
[2020-01-19 20:00:20,380] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-08 00:00:00: scheduled__2015-07-08T00:00:00, externally triggered: False>
[2020-01-19 20:00:20,394] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-09 00:00:00: scheduled__2015-07-09T00:00:00, externally triggered: False>
[2020-01-19 20:00:20,407] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 20:00:20,417] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-09 00:00:00 [scheduled]> in ORM
[2020-01-19 20:00:20,425] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-09 00:00:00 [scheduled]> in ORM
[2020-01-19 20:00:20,440] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.286 seconds
[2020-01-19 20:01:45,075] {jobs.py:368} INFO - Started process (PID=94960) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:01:50,084] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 20:01:50,087] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 20:01:53,234] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:01:53,465] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 20:01:53,533] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-10 00:00:00: scheduled__2015-07-10T00:00:00, externally triggered: False>
[2020-01-19 20:01:53,536] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-09 00:00:00: scheduled__2015-07-09T00:00:00, externally triggered: False>
[2020-01-19 20:01:53,558] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-10 00:00:00: scheduled__2015-07-10T00:00:00, externally triggered: False>
[2020-01-19 20:01:53,578] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 20:01:53,589] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-10 00:00:00 [scheduled]> in ORM
[2020-01-19 20:01:53,595] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-10 00:00:00 [scheduled]> in ORM
[2020-01-19 20:01:53,611] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.537 seconds
[2020-01-19 20:03:19,015] {jobs.py:368} INFO - Started process (PID=95676) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:03:24,018] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 20:03:24,020] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 20:03:29,380] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:03:29,781] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 20:03:29,854] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-11 00:00:00: scheduled__2015-07-11T00:00:00, externally triggered: False>
[2020-01-19 20:03:29,868] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-10 00:00:00: scheduled__2015-07-10T00:00:00, externally triggered: False>
[2020-01-19 20:03:29,934] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-11 00:00:00: scheduled__2015-07-11T00:00:00, externally triggered: False>
[2020-01-19 20:03:30,005] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 20:03:30,028] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-11 00:00:00 [scheduled]> in ORM
[2020-01-19 20:03:30,042] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-11 00:00:00 [scheduled]> in ORM
[2020-01-19 20:03:30,075] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 11.060 seconds
[2020-01-19 20:04:55,725] {jobs.py:368} INFO - Started process (PID=96435) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:05:00,735] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 20:05:00,738] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 20:05:03,508] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:05:03,661] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 20:05:03,684] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-12 00:00:00: scheduled__2015-07-12T00:00:00, externally triggered: False>
[2020-01-19 20:05:03,687] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-11 00:00:00: scheduled__2015-07-11T00:00:00, externally triggered: False>
[2020-01-19 20:05:03,700] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-12 00:00:00: scheduled__2015-07-12T00:00:00, externally triggered: False>
[2020-01-19 20:05:03,714] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 20:05:03,725] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-12 00:00:00 [scheduled]> in ORM
[2020-01-19 20:05:03,730] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-12 00:00:00 [scheduled]> in ORM
[2020-01-19 20:05:03,746] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.021 seconds
[2020-01-19 20:06:22,459] {jobs.py:368} INFO - Started process (PID=96928) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:06:27,465] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 20:06:27,467] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 20:06:30,362] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:06:30,511] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 20:06:30,543] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-13 00:00:00: scheduled__2015-07-13T00:00:00, externally triggered: False>
[2020-01-19 20:06:30,546] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-12 00:00:00: scheduled__2015-07-12T00:00:00, externally triggered: False>
[2020-01-19 20:06:30,562] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-13 00:00:00: scheduled__2015-07-13T00:00:00, externally triggered: False>
[2020-01-19 20:06:30,574] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 20:06:30,584] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-13 00:00:00 [scheduled]> in ORM
[2020-01-19 20:06:30,590] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-13 00:00:00 [scheduled]> in ORM
[2020-01-19 20:06:30,605] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.146 seconds
[2020-01-19 20:07:56,343] {jobs.py:368} INFO - Started process (PID=97407) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:08:01,353] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 20:08:01,356] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 20:08:07,516] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:08:07,773] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 20:08:07,828] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-14 00:00:00: scheduled__2015-07-14T00:00:00, externally triggered: False>
[2020-01-19 20:08:07,833] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-13 00:00:00: scheduled__2015-07-13T00:00:00, externally triggered: False>
[2020-01-19 20:08:07,853] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-14 00:00:00: scheduled__2015-07-14T00:00:00, externally triggered: False>
[2020-01-19 20:08:07,874] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 20:08:07,888] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-14 00:00:00 [scheduled]> in ORM
[2020-01-19 20:08:07,898] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-14 00:00:00 [scheduled]> in ORM
[2020-01-19 20:08:07,915] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 11.572 seconds
[2020-01-19 20:09:34,887] {jobs.py:368} INFO - Started process (PID=97944) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:09:39,897] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 20:09:39,899] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 20:09:42,748] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:09:42,931] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 20:09:42,958] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-15 00:00:00: scheduled__2015-07-15T00:00:00, externally triggered: False>
[2020-01-19 20:09:42,961] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-14 00:00:00: scheduled__2015-07-14T00:00:00, externally triggered: False>
[2020-01-19 20:09:42,975] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-15 00:00:00: scheduled__2015-07-15T00:00:00, externally triggered: False>
[2020-01-19 20:09:42,988] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 20:09:43,000] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-15 00:00:00 [scheduled]> in ORM
[2020-01-19 20:09:43,008] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-15 00:00:00 [scheduled]> in ORM
[2020-01-19 20:09:43,024] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.137 seconds
[2020-01-19 20:11:07,608] {jobs.py:368} INFO - Started process (PID=98605) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:11:12,616] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 20:11:12,621] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 20:11:15,722] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:11:15,865] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 20:11:15,892] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-16 00:00:00: scheduled__2015-07-16T00:00:00, externally triggered: False>
[2020-01-19 20:11:15,895] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-15 00:00:00: scheduled__2015-07-15T00:00:00, externally triggered: False>
[2020-01-19 20:11:15,905] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-16 00:00:00: scheduled__2015-07-16T00:00:00, externally triggered: False>
[2020-01-19 20:11:15,916] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 20:11:15,925] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-16 00:00:00 [scheduled]> in ORM
[2020-01-19 20:11:15,932] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-16 00:00:00 [scheduled]> in ORM
[2020-01-19 20:11:15,947] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.339 seconds
[2020-01-19 20:12:40,848] {jobs.py:368} INFO - Started process (PID=99211) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:12:45,855] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 20:12:45,857] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 20:12:48,998] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:12:49,184] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 20:12:49,211] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-17 00:00:00: scheduled__2015-07-17T00:00:00, externally triggered: False>
[2020-01-19 20:12:49,214] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-16 00:00:00: scheduled__2015-07-16T00:00:00, externally triggered: False>
[2020-01-19 20:12:49,226] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-17 00:00:00: scheduled__2015-07-17T00:00:00, externally triggered: False>
[2020-01-19 20:12:49,236] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 20:12:49,246] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-17 00:00:00 [scheduled]> in ORM
[2020-01-19 20:12:49,253] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-17 00:00:00 [scheduled]> in ORM
[2020-01-19 20:12:49,267] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.420 seconds
[2020-01-19 20:14:10,097] {jobs.py:368} INFO - Started process (PID=99756) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:14:15,104] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 20:14:15,106] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 20:14:19,115] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:14:19,360] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 20:14:19,391] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-18 00:00:00: scheduled__2015-07-18T00:00:00, externally triggered: False>
[2020-01-19 20:14:19,396] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-17 00:00:00: scheduled__2015-07-17T00:00:00, externally triggered: False>
[2020-01-19 20:14:19,410] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-18 00:00:00: scheduled__2015-07-18T00:00:00, externally triggered: False>
[2020-01-19 20:14:19,421] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 20:14:19,435] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-18 00:00:00 [scheduled]> in ORM
[2020-01-19 20:14:19,443] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-18 00:00:00 [scheduled]> in ORM
[2020-01-19 20:14:19,459] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 9.362 seconds
[2020-01-19 20:15:50,737] {jobs.py:368} INFO - Started process (PID=476) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:15:55,744] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 20:15:55,746] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 20:15:58,738] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:15:58,902] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 20:15:58,924] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-19 00:00:00: scheduled__2015-07-19T00:00:00, externally triggered: False>
[2020-01-19 20:15:58,927] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-18 00:00:00: scheduled__2015-07-18T00:00:00, externally triggered: False>
[2020-01-19 20:15:58,937] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-19 00:00:00: scheduled__2015-07-19T00:00:00, externally triggered: False>
[2020-01-19 20:15:58,947] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 20:15:58,956] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-19 00:00:00 [scheduled]> in ORM
[2020-01-19 20:15:58,962] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-19 00:00:00 [scheduled]> in ORM
[2020-01-19 20:15:58,976] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.239 seconds
[2020-01-19 20:17:23,459] {jobs.py:368} INFO - Started process (PID=1051) to work on /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:17:28,467] {jobs.py:562} ERROR - Cannot use more than 1 thread when using sqlite. Setting max_threads to 1
[2020-01-19 20:17:28,472] {jobs.py:1742} INFO - Processing file /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py for tasks to queue
[2020-01-19 20:17:31,460] {jobs.py:1754} INFO - DAG(s) dict_keys(['latest_only', 'example_python_operator', 'test_utils', 'example_bash_operator', 'example_short_circuit_operator', 'example_branch_operator', 'tutorial', 'example_passing_params_via_test_command', 'latest_only_with_trigger', 'example_xcom', 'example_http_operator', 'example_skip_dag', 'example_trigger_target_dag', 'example_branch_dop_operator_v3', 'example_subdag_operator', 'example_subdag_operator.section-1', 'example_subdag_operator.section-2', 'example_trigger_controller_dag', 'pipeline']) retrieved from /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py
[2020-01-19 20:17:31,697] {jobs.py:1386} INFO - Processing pipeline
[2020-01-19 20:17:31,735] {jobs.py:1390} INFO - Created <DagRun pipeline @ 2015-07-20 00:00:00: scheduled__2015-07-20T00:00:00, externally triggered: False>
[2020-01-19 20:17:31,739] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-19 00:00:00: scheduled__2015-07-19T00:00:00, externally triggered: False>
[2020-01-19 20:17:31,754] {jobs.py:895} INFO - Examining DAG run <DagRun pipeline @ 2015-07-20 00:00:00: scheduled__2015-07-20T00:00:00, externally triggered: False>
[2020-01-19 20:17:31,768] {jobs.py:594} INFO - Skipping SLA check for <DAG: pipeline> because no tasks in DAG have SLAs
[2020-01-19 20:17:31,778] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.trainer 2015-07-20 00:00:00 [scheduled]> in ORM
[2020-01-19 20:17:31,784] {jobs.py:1819} INFO - Creating / updating <TaskInstance: pipeline.test_predict 2015-07-20 00:00:00 [scheduled]> in ORM
[2020-01-19 20:17:31,799] {jobs.py:375} INFO - Processing /Users/yukikatoh/Documents/devops_nd/capstone/ml/dags/pipeline.py took 8.340 seconds
